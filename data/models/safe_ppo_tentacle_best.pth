{
  "model_type": "best_performance",
  "algorithm": "Safe_PPO",
  "robot_type": "tentacle",
  "selection_criteria": "highest_safety_score",
  "performance_metrics": {
    "final_reward": 27.3,
    "safety_score": 0.98,
    "success_rate": 0.95,
    "training_episodes": 1000,
    "convergence_episode": 562
  },
  "model_architecture": {
    "policy_network": {
      "input_dim": 24,
      "hidden_layers": [256, 256],
      "output_dim": 8,
      "activation": "ReLU",
      "dropout_rate": 0.1
    },
    "value_network": {
      "input_dim": 24,
      "hidden_layers": [256, 256],
      "output_dim": 1
    },
    "cost_network": {
      "input_dim": 24,
      "hidden_layers": [128, 128],
      "output_dim": 1
    }
  },
  "hyperparameters": {
    "learning_rate": 3e-4,
    "batch_size": 64,
    "clip_range": 0.2,
    "entropy_coef": 0.01,
    "value_loss_coef": 0.5,
    "cost_limit": 25.0,
    "lagrange_multiplier_lr": 1e-3
  },
  "training_info": {
    "total_parameters": 218543,
    "training_time_hours": 3.1,
    "gpu_memory_gb": 2.9,
    "creation_date": "2024-01-15T14:30:00"
  }
}